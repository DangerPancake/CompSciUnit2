### Exploring the ethics of using a chatbot to provide advice.
#### Problems arise from the following:
  #### Lack of emotion and emotional foresight
    Chatbots look at just what the user inputs and because of that there is no foresight on the impacts of the advice given or the user's situation
    Chatbots are inherently not human and because of that don't have the user's best interests in mind; it depends on the data used to train the model
  #### Lack of medical expertise
    In the case of mental health issues, therapists and the like have to go through extensive training. Chatbots don't have said training.
  #### If a user discloses a crime then a chatbot won't report this in contrast to a human
    This isn't inherently unethical but is a **problem**
  #### Advice chatbots give is just an amalgamation of the data used to train it
    this depends on what the sample is but it is likely it won't be the best
  #### Data Collection
    Chatbots collect data and because of that there is all the ethics introduced as for what to do with the data and such
  #### Conclusion
  It really comes down to a few things:
    # The chatbot doesn't have medical expertise and doesn't actually know what it is saying most of the time
    # Are users disclosing crimes required to be reported? How does the chatbot detect this (can't have false positives!)
    # Do we store user data? how and for what purpose?
    # How do we train the chatbot? The dataset used for training heavily impacts the advice given

### 5 Ethical metrics
#### Non-maleficence - Avoid causing physical, social or mental harm to users
#### Beneficence - Ensure that interventions do good or provide real benefit to users
#### Respect - for autonomy	Respect usersâ€™ values and choices
#### Justice - Treat users without unfair bias, discrimination or inequity
#### Explicability - Provide to users sufficient transparency about the nature and effects of the technology and be accountable for its design and deployment
#### *(Completely stolen from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10291862/)*
